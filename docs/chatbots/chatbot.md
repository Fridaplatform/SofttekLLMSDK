# Chatbot

The Chatbot class is the main class of the library. It is used to initialize a chatbot instance, which can then be used to chat with an LLM.

### Index

- [Chatbot](#chatbot-1)

## Chatbot

```python
Chatbot(
  model: LLMModel,
  description: str | None = None,
  memory: Memory = WindowMemory(window_size=10),
  non_valid_response: str | None = None,
  filters: List[Filter] | None = None,
  cache: Cache | None = None,
  cache_probability: float = 0.5,
  verbose: bool = False,
)
```

The `Chatbot` class is the main class of the library. It is used to initialize a chatbot instance, which can then be used to chat with an [LLM](../models.md).

#### Args

- `model` ([`LLMModel`](../models.md)): LLM model used by the chatbot.
- `description` (`str | None`, optional): Information about the chatbot. Defaults to `None`.
- `memory` ([`Memory`](../memory.md), optional): Memory used by the chatbot. Defaults to [`WindowMemory`](../memory.md)`(window_size=10)`.
- `non_valid_response` (`str | None`, optional): [`Response`](../schemas/response.md) given when the prompt does not follow the rules set by the `filters`. Defaults to `None`. If `None`, an [`InvalidPrompt`](../exceptions.md) exception is raised when the prompt does not follow the rules set by the `filters`.
- `filters` (`List[`[`Filter`](../schemas/filter.md)`] | None`, optional): List of filters used by the chatbot. Defaults to `None`.
- `cache` ([`Cache`](../cache.md)` | None`, optional): Cache used by the chatbot. Defaults to `None`.
- `cache_probability` (`float`, optional): Probability of using the [`cache`](../cache.md). Defaults to `0.5`. If `1.0`, the cache is **always used**. If `0.0`, the cache is **never used**.
- `verbose` (`bool`, optional): Whether to print additional information. Defaults to `False`.

### Properties

- `model`: The [model](../models.md) used by the chatbot.
- `memory`: The [memory](../memory.md) used by the chatbot.
- `description`: Information about the chatbot.
- `filters`: The [filters](../schemas/filter.md) used by the chatbot.
- `cache`: The [cache](../cache.md) used by the chatbot.
- `cache_probability`: The probability of using the [cache](../cache.md).
- `verbose`: Whether to print additional information.

### Methods

```python
chat(
  prompt: str,
  print_cache_score: bool = False,
  cache_kwargs: Dict = {},
  logging_kwargs: Dict | None = None,
) -> Response
```

Chatbot function that returns a [response](../schemas/response.md) given a `prompt`. If a [memory](../memory.md) and/or [cache](../cache.md) are available, it considers **previously stored conversations**. [`Filters`](../schemas/filter.md) are applied to the `prompt` before processing to ensure it is valid.

#### Args

- `prompt` (`str`): user's input string text
- `print_cache_score` (`bool`, optional): whether to print the [cache](../cache.md) score. Defaults to `False`.
- `cache_kwargs` (`Dict`, optional): additional keyword arguments to be passed to the [cache](../cache.md). Defaults to `{}`.
- `logging_kwargs` (`Dict`, optional): additional keyword arguments to be passed to the logging function. **Can only be used with certain [models](../models.md)**. Defaults to `None`.

#### Raises

- [`InvalidPrompt`](../exceptions.md): If the `prompt` does not follow the rules set by the [filters](../schemas/filter.md) and **`non_valid_response` is `None`**.

#### Returns

- [`Response`](../schemas/response.md): the response message object generated by the chatbot, including its content and metadata.
